{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn  as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv',sep=\";\")\n",
    "white_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a new column called 'quality label' based on the score in the existing column 'quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine['quality_label'] = red_wine['quality'].apply(lambda value: 'low'\n",
    "if value <= 5 else 'medium'\n",
    "if value <= 7 else 'high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine['quality_label'] = white_wine['quality'].apply(lambda value: 'low'\n",
    "if value <= 5 else 'medium'\n",
    "if value <= 7 else 'high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines the red and white wine dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "6492            6.2              0.21         0.29             1.6      0.039   \n",
       "6493            6.6              0.32         0.36             8.0      0.047   \n",
       "6494            6.5              0.24         0.19             1.2      0.041   \n",
       "6495            5.5              0.29         0.30             1.1      0.022   \n",
       "6496            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "6492                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "6493                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "6494                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "6495                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "6496                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality quality_label  \n",
       "6492     11.2        6        medium  \n",
       "6493      9.6        5           low  \n",
       "6494      9.4        6        medium  \n",
       "6495     12.8        7        medium  \n",
       "6496     11.8        6        medium  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined=pd.concat([red_wine, white_wine], ignore_index=True)\n",
    "combined.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the values from 'quality label', creates a new column with the mapped labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     quality_label  encoded_quality_label\n",
      "0              low                      0\n",
      "1              low                      0\n",
      "2              low                      0\n",
      "3           medium                      1\n",
      "4              low                      0\n",
      "...            ...                    ...\n",
      "5313        medium                      1\n",
      "5314           low                      0\n",
      "5315        medium                      1\n",
      "5316        medium                      1\n",
      "5317        medium                      1\n",
      "\n",
      "[5318 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "\n",
    "combined['encoded_quality_label'] = combined['quality_label'].map(label_mapping) \n",
    "\n",
    "print(combined[['quality_label', 'encoded_quality_label']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Encoding categorical variables-->Ordinal variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder--> NOT FOR CATHGORICAL CLASSES \n",
    "\n",
    "#combined_wine = pd.concat([red_wine, white_wine], ignore_index=True)\n",
    "\n",
    "# Select the column to be encoded\n",
    "#C = combined_wine[['quality_label']]\n",
    "\n",
    "# Create and fit the encoder \n",
    "#label_encoder = LabelEncoder()\n",
    "#encoded_labels = label_encoder.fit_transform(C['quality_label'])\n",
    "\n",
    "# Add the encoded labels as a new column\n",
    "#combined_wine['encoded_quality_label'] = encoded_labels\n",
    "\n",
    "# Save the DataFrame with encoded column\n",
    "#combined_wine.to_csv('combined_wine_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5318 entries, 0 to 5317\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   fixed acidity          5318 non-null   float64\n",
      " 1   volatile acidity       5318 non-null   float64\n",
      " 2   citric acid            5318 non-null   float64\n",
      " 3   residual sugar         5318 non-null   float64\n",
      " 4   chlorides              5318 non-null   float64\n",
      " 5   free sulfur dioxide    5318 non-null   float64\n",
      " 6   total sulfur dioxide   5318 non-null   float64\n",
      " 7   density                5318 non-null   float64\n",
      " 8   pH                     5318 non-null   float64\n",
      " 9   sulphates              5318 non-null   float64\n",
      " 10  alcohol                5318 non-null   float64\n",
      " 11  quality                5318 non-null   int64  \n",
      " 12  quality_label          5318 non-null   object \n",
      " 13  encoded_quality_label  5318 non-null   int64  \n",
      "dtypes: float64(11), int64(2), object(1)\n",
      "memory usage: 581.8+ KB\n"
     ]
    }
   ],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_wine[\"encoded_quality_label\"]=combined_wine.encoded_quality_label.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_wine[\"quality_label\"]=combined_wine.quality_label.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = combined.drop([\"encoded_quality_label\", \"quality_label\", \"quality\"], axis=1)\n",
    "y = combined[\"encoded_quality_label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# StratifiedKFold with 4 folds\n",
    "stratified_kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4254, 11)\n",
      "(4254,)\n",
      "(1064, 11)\n",
      "(1064,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of wines: (4254, 11)\n",
      "Shape of quality: (4254,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of wines:\", X_train.shape)\n",
    "print(\"Shape of quality:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.041</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.98949</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.39</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.055</td>\n",
       "      <td>17.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.99250</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.031</td>\n",
       "      <td>37.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99220</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.057</td>\n",
       "      <td>131.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.59</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.067</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.18</td>\n",
       "      <td>1.36</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4697            6.6              0.23         0.32             1.5      0.041   \n",
       "5032            6.4              0.30         0.27             4.4      0.055   \n",
       "3750            6.1              0.16         0.37             1.1      0.031   \n",
       "1634            7.5              0.27         0.31             5.8      0.057   \n",
       "555             8.9              0.29         0.35             1.9      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4697                  8.0                  72.0  0.98949  3.22       0.39   \n",
       "5032                 17.0                 135.0  0.99250  3.23       0.44   \n",
       "3750                 37.0                  97.0  0.99220  3.40       0.58   \n",
       "1634                131.0                 313.0  0.99460  3.18       0.59   \n",
       "555                  25.0                  57.0  0.99700  3.18       1.36   \n",
       "\n",
       "      alcohol  \n",
       "4697     12.7  \n",
       "5032     12.2  \n",
       "3750     10.5  \n",
       "1634     10.5  \n",
       "555      10.3  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3842    1\n",
       "511     1\n",
       "62      0\n",
       "4756    0\n",
       "3683    0\n",
       "Name: encoded_quality_label, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data is skewed--> feature scaling-->normalisation technique:MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fits scaler on training data,transforms training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "norm = MinMaxScaler().fit(X_train)\n",
    "X_train_norm = norm.transform(X_train)\n",
    "X_test_norm = norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model & Evaluate the model (Create and fit the RandomForestClassifier with class weights using cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Fold 1: 73.7781954887218\n",
      "Accuracy on Fold 2: 70.86466165413535\n",
      "Accuracy on Fold 3: 73.47130761994356\n",
      "Accuracy on Fold 4: 74.03574788334902\n",
      "Average Accuracy with class weights and StratifiedKFold: 73.03747816153744\n",
      "Accuracy on the test set: 75.09398496240601\n",
      "Training Accuracy: 0.8982134461683122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50 , min_samples_split= 10, min_samples_leaf= 4 , max_depth= 40)\n",
    "cross_val_scores = cross_val_score(rf, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "\n",
    "# Prints the accuracy FOR EACH fold\n",
    "for fold, accuracy in enumerate(cross_val_scores, 1):\n",
    "    print(f\"Accuracy on Fold {fold}: {accuracy * 100}\")\n",
    "\n",
    "# AVERAGE accuracy across folds\n",
    "average_accuracy = cross_val_scores.mean()\n",
    "print(\"Average Accuracy with class weights and StratifiedKFold:\", average_accuracy * 100)\n",
    "\n",
    "# FitS the model on the entire training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# CalculateS and printS the accuracy on the TEST set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on the test set:\", test_accuracy * 100) \n",
    "print(\"Training Accuracy:\", rf.score(X_train, y_train))\n",
    "#print(\"Cohens kappa:\",rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A balanced accuracy of around 50% indicates that the model is performing no better than random chance on your dataset. In the context of classification tasks, 50% balanced accuracy suggests that the model is not effectively discriminating between classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy with class weights: 49.61771339266497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy with class weights:\", balanced_acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix for  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Random Forest:\n",
      "[[255 128   0]\n",
      " [108 543   0]\n",
      " [  0  30   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix Random Forest:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "True Positives (TP):\n",
    "\n",
    "Class 1 (low quality): 255 instances correctly predicted.\n",
    "Class 2 (medium quality): 543 instances correctly predicted.\n",
    "Class 3 (high quality): 0 instances correctly predicted.\n",
    "30 false negatives --> predicted as medium quality but actually high "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score for RandomForest: 73.75517858827631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  \n",
    "\n",
    "print(\"Weighted F1 Score for RandomForest:\", f1*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weighted F1 score of 0.7375 indicates the overall performance of your Random Forest model in terms of precision and recall, considering the class imbalance in your dataset. The weighted F1 score takes into account the contribution of each class based on its proportion in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for RandomForest: 0.47267456159309584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "print(\"Cohen's Kappa for RandomForest:\", kappa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning for RandomForest ( RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dariy\\OneDrive\\Работен плот\\Code Academy\\Python\\Project_ML_Wine.ipynb Cell 39\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m random_search \u001b[39m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     rf,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     param_distributions\u001b[39m=\u001b[39mparam_dist,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Fits RandomizedSearchCV to the training data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m random_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Gets the best hyperparameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dariy/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B5%D0%BD%20%D0%BF%D0%BB%D0%BE%D1%82/Code%20Academy/Python/Project_ML_Wine.ipynb#X53sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m best_params \u001b[39m=\u001b[39m random_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1805\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1806\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1807\u001b[0m         ParameterSampler(\n\u001b[0;32m   1808\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_distributions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter, random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state\n\u001b[0;32m   1809\u001b[0m         )\n\u001b[0;32m   1810\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthreads\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39mcurr_sample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dariy\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  \n",
    "    scoring='accuracy',  \n",
    "    cv=4,  # 4 cross-validation folds\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fits RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Gets the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Trains a model with the best hyperparameters\n",
    "best_rf_model = RandomForestClassifier(random_state=42, **best_params)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluates the model on the test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy on Test Set:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Cohen's Kappa coefficient of 1.0 indicates perfect agreement between the predicted labels and the true labels in your Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbor Training Accuracy: 0.7569346497414199\n",
      "Support Vector Machine (Linear Classifier) Training Accuracy: 0.5397273154677951\n",
      "Support Vector Machine (RBF Classifier) Training Accuracy: 0.5961448048895157\n",
      "Gaussian Naive Bayes Training Accuracy: 0.6391631405735778\n",
      "KNeighborsClassifier:\n",
      "Cross-Validation Accuracy: 63.33%\n",
      "SVC:\n",
      "Cross-Validation Accuracy: 53.48%\n",
      "SVC:\n",
      "Cross-Validation Accuracy: 59.31%\n",
      "GaussianNB:\n",
      "Cross-Validation Accuracy: 63.47%\n"
     ]
    }
   ],
   "source": [
    "# Creates a function that shows the Accuracy and the Cross-Validation Accuracy of different Machine Learning Models \n",
    "\n",
    "def cross_validate_models(models, X_train, y_train):\n",
    "    for model in models:\n",
    "        print(f'{model.__class__.__name__}:')\n",
    "\n",
    "        # Perform k-fold cross-validation\n",
    "        stratified_kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "        cross_val_acc = cross_val_score(model, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "\n",
    "        print(f'Cross-Validation Accuracy: {cross_val_acc.mean() * 100:.2f}%')       \n",
    "def models(X_train,y_train, X_test, y_test):\n",
    "#Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  knn= KNeighborsClassifier(n_neighbors = 5, weights = 'uniform', metric = 'minkowski', p = 1)\n",
    "  knn.fit(X_train, y_train)  \n",
    "\n",
    "  # Using SVC method of svm class to use Support Vector Machine Algorithm\n",
    "  from sklearn.svm import SVC\n",
    "  svc_lin = SVC(kernel = 'linear', random_state = 0, class_weight=\"balanced\")\n",
    "  svc_lin.fit(X_train, y_train)\n",
    "\n",
    "  # #Using SVC method of svm class to use Kernel SVM Algorithm\n",
    "  from sklearn.svm import SVC\n",
    "  svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n",
    "  svc_rbf.fit(X_train, y_train)\n",
    "\n",
    "  # #Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  gauss = GaussianNB()\n",
    "  gauss.fit(X_train, y_train)\n",
    "\n",
    "  print('K Nearest Neighbor Training Accuracy:', knn.score(X_train, y_train))\n",
    "  print('Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, y_train))\n",
    "  print('Support Vector Machine (RBF Classifier) Training Accuracy:', svc_rbf.score(X_train, y_train))\n",
    "  print('Gaussian Naive Bayes Training Accuracy:', gauss.score(X_train, y_train))\n",
    "\n",
    "  return knn, svc_lin, svc_rbf, gauss \n",
    "\n",
    "knn_model, svc_lin_model, svc_rbf_model, gauss_model = models(X_train, y_train, X_test, y_test)\n",
    "cross_validate_models([knn_model, svc_lin_model, svc_rbf_model, gauss_model], X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy for KNeighborsClassifier: 41.88%\n",
      "Balanced Accuracy for SVC: 63.49%\n",
      "Balanced Accuracy for SVC: 34.60%\n",
      "Balanced Accuracy for GaussianNB: 49.97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate and print balanced accuracy\n",
    "        balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        print(f'Balanced Accuracy for {model_name}: {balanced_acc * 100:.2f}%')\n",
    "\n",
    "models_list = [knn_model, svc_lin_model, svc_rbf_model, gauss_model]\n",
    "evaluate_models(models_list, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Training and Test Accuracies knn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7569346497414199\n",
      "Test Accuracy: 0.6456766917293233\n",
      "Potential overfitting: Training accuracy is higher than test accuracy.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "y_train_pred = knn_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "\n",
    "y_test_pred = knn_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "if train_accuracy > test_accuracy:\n",
    "    print(\"Potential overfitting: Training accuracy is higher than test accuracy.\")\n",
    "else:\n",
    "    print(\"Balanced performance: Training and test accuracies are comparable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamether tuning for knn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for knn: {'weights': 'distance', 'p': 1, 'n_neighbors': 13}\n",
      "Test Accuracy with Best Model: 0.6644736842105263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import numpy as np\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': np.random.randint(1, 20, 10),  # Random integers from 1 to 20\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "# Step 4: Perform RandomizedSearchCV with cross-validation\n",
    "random_search = RandomizedSearchCV(knn_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Hyperparameters for knn:\", best_params)\n",
    "\n",
    "# Step 6: Evaluate the model on the test set\n",
    "best_knn_model = random_search.best_estimator_\n",
    "test_accuracy = best_knn_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy with Best Model:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matriy for knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix knn:\n",
      "[[187 196   0]\n",
      " [151 500   0]\n",
      " [  4  26   0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_1 = knn_model.predict(X_test)\n",
    "conf_matrix_1 = confusion_matrix(y_test, y_pred_1)\n",
    "\n",
    "print(\"Confusion Matrix knn:\")\n",
    "print(conf_matrix_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "151 medium quality wines predictes as low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for KNN: 0.47267456159309584\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_1 = knn_model.predict(X_test)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "print(\"Cohen's Kappa for KNN:\", kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Training and Test Accuracies svc; WITHOUT CROSS-VALIDATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7226140103432064\n",
      "Test Accuracy: 0.7124060150375939\n",
      "Potential overfitting: Training accuracy is higher than test accuracy.\n"
     ]
    }
   ],
   "source": [
    "svc_lin_model\n",
    "\n",
    "y_train_pred = svc_lin_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "\n",
    "y_test_pred = svc_lin_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "#if train_accuracy > test_accuracy:\n",
    "    print(\"Potential overfitting: Training accuracy is higher than test accuracy.\")\n",
    "#else:\n",
    "    print(\"Balanced performance: Training and test accuracies are comparable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix for svc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix svc:\n",
      "[[225 158   0]\n",
      " [118 533   0]\n",
      " [  0  30   0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = svc_lin_model.predict(X_test)\n",
    "conf_matrix2 = confusion_matrix(y_test, y_pred2)\n",
    "\n",
    "print(\"Confusion Matrix svc:\")\n",
    "print(conf_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score for svc: 0.6984988878419696\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred2 = svc_lin_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred2, average='weighted')  \n",
    "\n",
    "print(\"Weighted F1 Score for svc:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for svc: 0.38725825999894603\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred2 = svc_lin_model.predict(X_test)\n",
    "kappa = cohen_kappa_score(y_test, y_pred2)\n",
    "\n",
    "print(\"Cohen's Kappa for svc:\", kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix with Cross VAl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for KNeighborsClassifier:\n",
      "[[187 196   0]\n",
      " [151 500   0]\n",
      " [  4  26   0]]\n",
      "\n",
      "\n",
      "Confusion Matrix for SVC:\n",
      "[[287  76  20]\n",
      " [183 253 215]\n",
      " [  0   7  23]]\n",
      "\n",
      "\n",
      "Confusion Matrix for SVC:\n",
      "[[ 24 359   0]\n",
      " [ 16 635   0]\n",
      " [  0  30   0]]\n",
      "\n",
      "\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[232 149   2]\n",
      " [147 473  31]\n",
      " [  0  25   5]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def print_confusion_matrix(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix for {model.__class__.__name__}:')\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print_confusion_matrix(knn_model, X_test, y_test)\n",
    "print_confusion_matrix(svc_lin_model, X_test, y_test)\n",
    "print_confusion_matrix(svc_rbf_model, X_test, y_test)\n",
    "print_confusion_matrix(gauss_model, X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score with Cross-Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for KNeighborsClassifier: 0.6313\n",
      "\n",
      "F1 Score for SVC: 0.5604\n",
      "\n",
      "F1 Score for SVC: 0.5048\n",
      "\n",
      "F1 Score for GaussianNB: 0.6693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def print_f1_score(model, X_test, y_test):\n",
    "   \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "  \n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  \n",
    "\n",
    "    \n",
    "    print(f'F1 Score for {model.__class__.__name__}: {f1:.4f}\\n')\n",
    "\n",
    "print_f1_score(knn_model, X_test, y_test)\n",
    "print_f1_score(svc_lin_model, X_test, y_test)\n",
    "print_f1_score(svc_rbf_model, X_test, y_test)\n",
    "print_f1_score(gauss_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohen´s Cappa Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for KNeighborsClassifier: 0.2447\n",
      "\n",
      "Cohen's Kappa for SVC: 0.2654\n",
      "\n",
      "Cohen's Kappa for SVC: 0.0427\n",
      "\n",
      "Cohen's Kappa for GaussianNB: 0.3329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def print_cohens_kappa(model, X_test, y_test):\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    print(f\"Cohen's Kappa for {model.__class__.__name__}: {kappa:.4f}\\n\")\n",
    "\n",
    "print_cohens_kappa(knn_model, X_test, y_test)\n",
    "print_cohens_kappa(svc_lin_model, X_test, y_test)\n",
    "print_cohens_kappa(svc_rbf_model, X_test, y_test)\n",
    "print_cohens_kappa(gauss_model, X_test, y_test)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
